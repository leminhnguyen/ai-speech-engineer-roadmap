
# ğŸ¥‘ ROADMAP: AI Speech Engineer

![GitHub stars](https://img.shields.io/github/stars/leminhnguyen/ai-speech-engineer-roadmap?style=social)
![GitHub forks](https://img.shields.io/github/forks/leminhnguyen/ai-speech-engineer-roadmap?style=social)
![GitHub last commit](https://img.shields.io/github/last-commit/leminhnguyen/ai-speech-engineer-roadmap)

> A curated roadmap based on my 5 years of experience form zero to become a skilled AI Speech Engineer. ğŸš€ğŸ‘¨â€ğŸ’»  
> This roadmap covers everything from fundamentals to cutting-edge research trends in the speech domain.

---

## ğŸ“… Overview Timeline

| Phase                        | Duration   | Focus Areas                               |
|-----------------------------|------------|-------------------------------------------|
| ğŸ§  Foundations              | 2 month    | Math, Python, Signal Processing           |
| ğŸ’¼ Tools & Frameworks       | 3 months   | Libraries, Audio Tools, Hugging Face      |
| ğŸŒ± Core Technologies        | 12 months   | ASR, TTS, Speaker Verification & Diarization |
| ğŸ”¬ Research Trends          | Continuous | Audio-Language Models                     |

---

## ğŸ§  #1 Foundations (1 month)

### ğŸ”¹ Python Basic
- ğŸ“º [Python Tutorial for Beginners](https://www.youtube.com/watch?v=YYXdXT2l-Gg&list=PL-osiE80TeTt2d9bfVyTiXJA-UTHn6WwU)

### ğŸ”¹ Audio Signal Processing for ML
- ğŸ“º [YouTube Series](https://www.youtube.com/watch?v=iCwMQJnKk2c&list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0)
- ğŸ“„ [Voice Processing PDF](materials/Voice-Processing-for-Machine-Learning.pdf)

---

## ğŸ’¼ #2 Tools & Frameworks (2 months)

### ğŸ§° Frameworks & Libraries
- âš™ï¸ PyTorch
- ğŸµ `librosa`, `torchaudio`
- ğŸ› ï¸ `ffmpeg`, `sox`

### ğŸ–¥ï¸ Tools
- ğŸ›ï¸ [Audacity](https://www.audacityteam.org/)
- ğŸ“º [Audacity Tutorial](https://www.youtube.com/watch?v=vlzOb4OLj94)

### ğŸ¤— Hugging Face Course
- ğŸ“š [Hugging Face Audio](https://huggingface.co/learn/audio-course/en/chapter1/audio_data)

---

## ğŸŒ± #3 Dive Into Speech Core Technologies (12 months)

### ğŸ™ï¸ Automatic Speech Recognition (ASR)
- ğŸ“˜ [SpeechBrain ASR](https://speechbrain.readthedocs.io/en/latest/tutorials/tasks/speech-recognition-from-scratch.html)
- ğŸ§ª [SpecAugment](https://blog.research.google/2019/04/specaugment-new-data-augmentation.html)
- ğŸ§  [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- ğŸ“„ [Google ASR Paper](https://storage.googleapis.com/gweb-research2023-media/pubtools/pdf/509254e34b4c496eb3cfa1c2be1e1b5fc874bee3.pdf)
- ğŸ“Š [Illustrated Wav2Vec2](https://jonathanbgn.com/2021/09/30/illustrated-wav2vec-2.html)
- ğŸ“ˆ [CTC](https://distill.pub/2017/ctc/)
- ğŸŒ¿ [Attention is All You Need](https://arxiv.org/abs/1706.03762)
- ğŸ§¾ [Wav2Vec2](https://arxiv.org/abs/2005.08100)
- ğŸ¤– [Whisper](https://arxiv.org/abs/2212.04356)
- ğŸ” [Fast Conformer](https://arxiv.org/abs/2305.05084)

### ğŸ—£ï¸ Text-to-Speech (TTS)
- ğŸ›ï¸ [My graduation thesis (Vietnamese)](materials/graduation-thesis.pdf)
- ğŸ“š [HMM-based Vietnamese TTS](https://theses.hal.science/tel-01260884/document)
- ğŸ“˜ [Wavenet](https://arxiv.org/abs/1609.03499)
- ğŸ§¾ [Tacotron 2](https://arxiv.org/abs/1703.10135)
- âš¡ [FastSpeech](https://arxiv.org/abs/1811.00002), [FastSpeech 2](https://arxiv.org/abs/2006.04558)
- ğŸ“ˆ [HiFi-GAN](https://arxiv.org/abs/2010.05646)
- ğŸ”Š [VITS](https://arxiv.org/abs/2106.06103), [HiFi-GAN](https://arxiv.org/abs/2010.05646)
- ğŸ” [JETS](https://arxiv.org/abs/2203.16852)
- ğŸŒ¿ [NaturalSpeech](https://arxiv.org/abs/2203.16852)

#### ğŸ‡»ğŸ‡³ Vietnamese Resources
- [Viphoneme](https://github.com/v-nhandt21/Viphoneme)
- [Text2PhonemeSequence](https://github.com/thelinhbkhn2014/Text2PhonemeSequence)

### ğŸ” Speaker Verification (SV)
- [Speech Verification Introduction](https://maelfabien.github.io/machinelearning/Speech1/#)
- [X-vector Paper](https://danielpovey.com/files/2017_interspeech_embeddings.pdf)
- [I-vector Paper](https://www.sciencedirect.com/science/article/pii/S1877050918314042/pdf)
- [ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation...](https://arxiv.org/abs/2005.07143)
- [VoxCeleb: a large-scale speaker identification dataset](https://arxiv.org/abs/1706.08612)
- [ResNeXt and Res2Net Structures for Speaker Verification](https://arxiv.org/abs/2007.02480)
- [Golden Gemini is All You Need: Finding the Sweet Spots for Speaker Verification](https://arxiv.org/abs/2312.03620)
- [CAM++: A Fast and Efficient Network for Speaker Verification Using Context-Aware Masking](https://arxiv.org/abs/2303.00332)
- [RedimNet: Reshape Dimensions Network for Speaker Recognition](https://arxiv.org/abs/2407.18223)
- [3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus...](https://arxiv.org/abs/2306.15354)
- [ERes2NetV2: Boosting Short-Duration Speaker...](https://arxiv.org/html/2406.02167v1)

### ğŸ‘¥ Speaker Diarization (SD)
- ğŸ“– [Speaker Diarization: An Introductory Overview](https://lajavaness.medium.com/speaker-diarization-an-introductory-overview-c070a3bfea70)
- [Speaker Diarization: From Traditional Methods to the Modern Models](https://leminhnguyen.github.io/post/speech-research/speaker-diarization/)
- [pyannote.audio: neural building blocks for speaker diarization](https://arxiv.org/abs/1911.01255)
- [A Review of Speaker Diarization: Recent Advances with Deep Learning](https://arxiv.org/abs/2101.09624)
- ğŸ†š [Comparing state-of-the-art speaker diarization frameworks : Pyannote vs Nemo](https://lajavaness.medium.com/comparing-state-of-the-art-speaker-diarization-frameworks-pyannote-vs-nemo-31a191c6300)
- [Multi-scale Speaker Diarization with Dynamic Scale Weighting](https://arxiv.org/pdf/2203.15974)
- [DiarizationLM: Speaker Diarization Post-Processing with Large Language Models](https://arxiv.org/html/2401.03506v10)
- [Sortformer: Seamless Integration of Speaker Diarization and ASR...](https://arxiv.org/abs/2409.06656)
---

## ğŸ”¬ #4 Research Trends

### ğŸ¤¯ Audio Language Models
- [Recent Advances in Speech Language Models: A Survey](https://arxiv.org/pdf/2410.03751)
- [Audio-Language Models for Audio-Centric Tasks: A survey](https://arxiv.org/pdf/2501.15177)
- [CosyVoice: A Scalable Multilingual Zero-shot Text to Speech...](https://arxiv.org/abs/2407.05407)
- [F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching](https://arxiv.org/abs/2410.06885)
- [FunAudioLLM: Voice Understanding and Generation Foundation Models...](https://arxiv.org/html/2407.04051v1)
- [Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale...](https://arxiv.org/abs/2311.07919)
- [MiniCPM: Unveiling the Potential of Small Language Models with Scalable...](https://arxiv.org/abs/2404.06395)
